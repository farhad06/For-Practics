{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMTp01LWrejj9ukT+Y+nPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhad06/For-Practics/blob/main/NLP/4_Tokenization_using_Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDUFIa-s6zDc",
        "outputId": "1f683493-2f73-49cc-84e8-b093c1f8d018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.blank('en')\n",
        "text=(\"When Sebastian Thrun started working on self-driving cars at.\"\n",
        "\" Google in 2007, few people outside of the company took him.\"\n",
        "\"The car of this self driving car is $90,0000\" )\n",
        "doc=nlp(text)"
      ],
      "metadata": {
        "id": "72NolevQ7HXZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_He1NGC7-iU",
        "outputId": "ef05ebc2-0e07-4608-b50d-6c8d27e79b07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When\n",
            "Sebastian\n",
            "Thrun\n",
            "started\n",
            "working\n",
            "on\n",
            "self\n",
            "-\n",
            "driving\n",
            "cars\n",
            "at\n",
            ".\n",
            "Google\n",
            "in\n",
            "2007\n",
            ",\n",
            "few\n",
            "people\n",
            "outside\n",
            "of\n",
            "the\n",
            "company\n",
            "took\n",
            "him\n",
            ".\n",
            "The\n",
            "car\n",
            "of\n",
            "this\n",
            "self\n",
            "driving\n",
            "car\n",
            "is\n",
            "$\n",
            "90,0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T4uxKfx8D4Q",
        "outputId": "afa163fc-09ab-4775-dbd3-e43642ec05d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "When"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token=doc[1]\n",
        "token.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uXn1xkKY8O2Y",
        "outputId": "bec970ea-2db4-4cbd-dd1b-c8e2b8f48481"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sebastian'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MKZR1Sn8TKl",
        "outputId": "4f2120b5-0186-411d-dadc-e9c0feeaac00"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collecting emails from a text file"
      ],
      "metadata": {
        "id": "yNuu7b1I_-4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/Student.txt\",'r') as f:\n",
        "  text=f.readlines()\n",
        "text  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ_pihGG8uJg",
        "outputId": "2fb80a5c-b2e5-43e9-db4e-4b05c248cb28"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name      \\t\\tDOB    \\t\\tE-Mail   \\t\\t\\t  Phone\\n',\n",
              " '------------\\t     ---------\\t       -----------    \\t\\t\\t ---------\\n',\n",
              " 'Farhad Ahamed\\t     4-12-1997\\t\\tiamfarhad@gmail.com\\t\\t9601545632\\n',\n",
              " '\\n',\n",
              " 'Topi \\t\\t     12-12-1995         234topi@gmail.com\\t\\t1256321477\\n',\n",
              " '\\n',\n",
              " 'Sakil\\t\\t     04-05-2000\\t\\tsakil23@yahoo.com               742563212333\\n',\n",
              " '\\n',\n",
              " 'Rohit Sharma\\t     11-08-1982         ro@hotmail.com\\t\\t\\t4578962115\\n',\n",
              " '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\" \".join(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "hK00We2kAf2E",
        "outputId": "9cd760cc-fa41-4111-fc64-a4228418621f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Name      \\t\\tDOB    \\t\\tE-Mail   \\t\\t\\t  Phone\\n ------------\\t     ---------\\t       -----------    \\t\\t\\t ---------\\n Farhad Ahamed\\t     4-12-1997\\t\\tiamfarhad@gmail.com\\t\\t9601545632\\n \\n Topi \\t\\t     12-12-1995         234topi@gmail.com\\t\\t1256321477\\n \\n Sakil\\t\\t     04-05-2000\\t\\tsakil23@yahoo.com               742563212333\\n \\n Rohit Sharma\\t     11-08-1982         ro@hotmail.com\\t\\t\\t4578962115\\n \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(text)\n",
        "email=[]\n",
        "for token in doc:\n",
        "  if token.like_email:\n",
        "    email.append(token.text)\n"
      ],
      "metadata": {
        "id": "wC6zDpW6A0be"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(email)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXUqrhzCBUnb",
        "outputId": "e243d308-4e13-4bca-8be1-bea8907cc8e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['iamfarhad@gmail.com', '234topi@gmail.com', 'sakil23@yahoo.com', 'ro@hotmail.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phone_numbers=[]\n",
        "for token in doc:\n",
        "  if token.like_num:\n",
        "    if len(token.text)==10:\n",
        "      phone_numbers.append(token.text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0JmX8hMjBXE6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phone_numbers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9sweU_lBybY",
        "outputId": "8309724f-eb5d-4380-e020-e34c76cc11a7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9601545632', '1256321477', '4578962115']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customizing Tokenizer"
      ],
      "metadata": {
        "id": "vxs_Yhc4Cwlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.symbols import ORTH"
      ],
      "metadata": {
        "id": "4qpzYp-SB0zM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.blank('en')\n",
        "doc=nlp('Thisis a text for using tokenizer')\n",
        "tokens=[token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQoMc_sLDfbH",
        "outputId": "c7c70bf6-b344-4249-f3fd-305849afa5b4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thisis', 'a', 'text', 'for', 'using', 'tokenizer']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a tokenizer manually\n",
        "nlp.tokenizer.add_special_case(\"Thisis\",[{ORTH:\"This\"},{ORTH:\"is\"}])\n",
        "doc=nlp('Thisis a text for using tokenizer')\n",
        "tokens=[token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN28T7reD5PM",
        "outputId": "bc1a4dff-841d-4bb4-e639-8c1f43695ac0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'a', 'text', 'for', 'using', 'tokenizer']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "_ciIp3rKEmFM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO7dTRh1Gx9V",
        "outputId": "ff24e67c-ff0a-4ae6-a3ff-b50506df4c31"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi7fZbOzHBpe",
        "outputId": "304da546-9213-4678-98f4-5a733c7051a4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f4dc169b220>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f4dc169bee0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f4dc2101510>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f4dc161f540>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f4dc1698b00>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f4dc2101660>)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbWkNMBmHF1c",
        "outputId": "99e27a9f-8944-4f79-bfb3-2bb07b2d1e4b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc ORG\n",
            "$45 billion MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "tfLrvFowHTa_",
        "outputId": "b224c7bc-acdf-46ce-a016-520055357367"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Tesla Inc\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is going to acquire twitter for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $45 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limmatization and Stemming Exercise\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BA5sLKdCJogD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "NxJ7K7khHXku"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#downloading all neccessary packages related to nltk\n",
        "# nltk.download('all')"
      ],
      "metadata": {
        "id": "bsoXlDB-KNv1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using stemming in nltk\n",
        "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
        "for token in lst_words:\n",
        "  print(token,\"======>\",stemmer.stem(token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htJsKdKKKTSg",
        "outputId": "1dddc8a4-3fc4-4b8e-cda0-4bbe3d5309df"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running ======> run\n",
            "painting ======> paint\n",
            "walking ======> walk\n",
            "dressing ======> dress\n",
            "likely ======> like\n",
            "children ======> children\n",
            "whom ======> whom\n",
            "good ======> good\n",
            "ate ======> ate\n",
            "fishing ======> fish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using lemmatization in spacy\n",
        "\n",
        "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token,\"======>\",token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UEtE2FoLSYN",
        "outputId": "9b904b98-990a-478a-e963-55cba7158b77"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running ======> run\n",
            "painting ======> painting\n",
            "walking ======> walking\n",
            "dressing ======> dress\n",
            "likely ======> likely\n",
            "children ======> child\n",
            "who ======> who\n",
            "good ======> good\n",
            "ate ======> eat\n",
            "fishing ======> fishing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
        "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gGrPvSbKLgSW"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_base_words=nltk.word_tokenize(text)\n",
        "base_words=[]\n",
        "for token in all_base_words:\n",
        "  base_word=stemmer.stem(token)\n",
        "  base_words.append(base_word)\n",
        "print(base_words)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3g5lLSzM9QY",
        "outputId": "888745c9-887c-4b73-9da1-ab019e2bc13d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['latha', 'is', 'veri', 'multi', 'talent', 'girl.sh', 'is', 'good', 'at', 'mani', 'skill', 'like', 'danc', ',', 'run', ',', 'sing', ',', 'playing.sh', 'also', 'like', 'eat', 'pav', 'bhagi', '.', 'she', 'ha', 'a', 'habit', 'of', 'fish', 'and', 'swim', 'too.besid', 'all', 'thi', ',', 'she', 'is', 'a', 'wonder', 'at', 'cook', 'too', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_text=' '.join(base_words)\n",
        "print(stem_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYzAM_LSNbrA",
        "outputId": "287d30d7-3b81-4207-8759-524daa0805ff"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(text)\n",
        "token_list=[token for token in doc]\n",
        "all_base_words=[token.lemma_ for token in doc]\n",
        "print(all_base_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGr3QmGlPdUo",
        "outputId": "79632e0a-7869-4a2f-ec7d-4a4cf3e5de3e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Latha', 'be', 'very', 'multi', 'talented', 'girl', '.', 'she', 'be', 'good', 'at', 'many', 'skill', 'like', 'dancing', ',', 'running', ',', 'singing', ',', 'play', '.', 'she', 'also', 'like', 'eat', 'Pav', 'Bhagi', '.', 'she', 'have', 'a', '\\n', 'habit', 'of', 'fishing', 'and', 'swim', 'too', '.', 'besides', 'all', 'this', ',', 'she', 'be', 'a', 'wonderful', 'at', 'cook', 'too', '.', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lema_text=' '.join(all_base_words)\n",
        "print(lema_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq0cp3eTQD-Z",
        "outputId": "fd82529f-0404-4f68-ef70-48270bfdc435"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n",
            " habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ttfElLcZSV7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}